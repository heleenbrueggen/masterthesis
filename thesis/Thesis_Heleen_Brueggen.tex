% \documentclass[10pt, a4paper, titlepage]{article}
\documentclass[3p,12pt,a4paper]{elsarticle}
% \usepackage[margin=1in]{geometry}
\usepackage{graphicx, latexsym}
% \usepackage{titling}
% \setlength{\droptitle}{-25em}
% \renewcommand{\maketitlehooka}{\Large}
\usepackage{setspace}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[export]{adjustbox}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{epstopdf}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage{multirow}
% \usepackage[labelfont=bf]{caption}
% \captionsetup{format=hang,justification=raggedright,singlelinecheck=false}
\usepackage[table,xcdraw]{xcolor}
\usepackage{colortbl}
\usepackage{lscape}
\usepackage{float}
\biboptions{sort&compress,round,semicolon,authoryear}
% \usepackage[sort&compress,round,semicolon,authoryear]{natbib}
\usepackage{bookmark}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1,1,1}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,    captionpos=t,                    
    keepspaces=true, numbers=left,                    
    numbersep=5pt, showspaces=false,                
    showstringspaces=false, showtabs=false, tabsize=2}
\lstset{style=mystyle}
\hypersetup{
    pdftitle={Master Thesis Heleen Brüggen},
    pdfauthor={Heleen Brüggen},
    pdfsubject={Master Thesis Heleen Brüggen},
    pdfkeywords={},
    bookmarksnumbered=true,
    bookmarksopen=true,
    bookmarksopenlevel=1,
    colorlinks=false,
    pdfstartview=Fit,
    pdfpagemode=UseNone
}

% \singlespacing%
\journal{Computational Statistics \& Data Analysis}

\begin{document}
% \begin{titlingpage}
% \begin{center}
% \Huge\textbf{Master Thesis:  \\ Multilevel Multivariate Imputation by Chained Equations through Bayesian Additive Regression Trees} \\
% \Large\textit{Methodology and Statistics for the Behavioural, Biomedical and Social Sciences}

% \vspace{.5cm}

% \normalsize\textit{Heleen Brüggen}

% % \vspace{11.5cm}
% \vspace{1cm}

% \begin{minipage}{1\textwidth}
% \begin{center}
% \section*{Abstract}
% \end{center}
% \end{minipage}

% \vspace{.25cm}

% \begin{minipage}{1\textwidth}
%     This study investigates whether the use of multilevel Bayesian Additive Regression Trees (BART) in a multilevel multiple imputation context improves the bias, coverage, and variance estimates of the multilevel model parameter estimates compared to current practices. At present, defining a congenial imputation model for a hierarchically structured dataset is an laborious process due to complicated non-linear relationships. Using a non-parametric, tree-based BART model as the imputation model might alleviate these complexities. A simulation study was conducted to evaluate the performance of multilevel-BART models in a multilevel imputation context. The population data-generating mechanism was based on a multilevel linear model with random intercepts, slopes, and cross-level interactions. The performance of multilevel-BART models was compared to single-level predictive mean matching (PMM), multilevel PMM, single-level BART and complete case analysis. The results show that the multilevel PMM model performed best in terms of bias, variance, and coverage of the parameter estimates. However, the multilevel-BART model showed promising results for the random intercepts and slopes. So, in its current form, multilevel-BART models do not offer an improvement over the existing implementation.
% \end{minipage}

% \vspace{4cm}

% \begin{minipage}{.5\textwidth}
% \begin{center}
%             \includegraphics[width=10cm]{graphs/UU_logo_2021_EN_RGB.png}
% \end{center}
% \end{minipage}%
    
% \vspace{.25cm}

% \begin{minipage}{0.5\textwidth}
% \begin{flushleft}

% \textbf{Word count:} \\
% \textbf{Candidate Journal:} \\
% \textbf{FETC Case Number:} \\
% \textbf{Research Archive:} \\
% \textbf{Supervisors:} \\
% T. Volker MSc. \\
% Dr. G. Vink \\
% H. Oberman MSc.
% \end{flushleft}
% \end{minipage}%
% \begin{minipage}{0.5\textwidth}
% \begin{flushright}

% 6450 \\ %detex thesis/Thesis_Heleen_Brueggen.tex | wc -w
% Computational Statistics \& Data Analysis \\
% 23-1778 \\
% \url{github.com/heleenbrueggen/masterthesis} \\
% ------------------------\\
% Utrecht University \\
% Utrecht University \\
% Utrecht University
% \end{flushright}
% \end{minipage}

% \end{center}
% \end{titlingpage}
\begin{frontmatter}
\title{Multilevel Multivariate Imputation by Chained Equations through Bayesian Additive Regression Trees\tnoteref{t1,t2}}
\tnotetext[t1]{\textbf{Word count} = 5952}
\tnotetext[t2]{\textbf{FETC Case Number} = 23-1778}
\tnotetext[t3]{\textbf{Candidate Journal} = Computational Statistics \& Data Analysis}
\tnotetext[t4]{\textbf{Research Archive} = \url{github.com/heleenbrueggen/masterthesis}}

\author[1]{Heleen Brüggen\fnref{fn1,fn2}}
\ead{h.bruggen@uu.nl}
\affiliation[1]{organization = {Methodology and Statistics for the Behavioural, Biomedical and Social Sciences},
                  address = {Utrecht Universty, The Netherlands}}

\fntext[fn1]{\textbf{Student number} = 6474292}
\fntext[fn2]{\textbf{Supervisors} = T. Volker MSc., Dr. G. Vink, H. Oberman MSc.}


\begin{abstract} % 173 words
    Defining a congenial imputation model for a hierarchically structured dataset is a laborious process due to complicated non-linear relationships. Using a non-parametric, tree-based BART model as the imputation model might accomplish this. This study investigates if, in a multilevel context, the use of Bayesian Additive Regression Trees (BART) in Multiple Imputation (MI) improves the bias, coverage, and variance estimates of model parameter estimates compared to current practices. The performance of multilevel-BART models were evaluated with a statistical simulation in a multilevel imputation context. The population data-generating mechanism was a multilevel linear model with random intercepts, slopes, and cross-level interactions. The multilevel-BART imputation models were compared to single-level predictive mean matching (PMM), multilevel PMM, single-level BART, and complete case analysis. The results show that the multilevel PMM model performed best in terms of bias, variance, and coverage of the parameter estimates. However, the multilevel-BART model showed promising results for the random intercepts and slopes. Nevertheless, in its current form, multilevel-BART models do not offer an improvement over the multilevel PMM.
\end{abstract}
\end{frontmatter}

\newpage
\tableofcontents
\newpage
\section{Introduction}
Incomplete data is a common challenge in many fields of research. Frequently used ad hoc strategies to deal with missing data, such as complete case analysis or mean imputation, often lead to erroneous inferences in realistic situations. Missingness can follow a multivariate mechanism that may depend on observed data --- or even unobserved data --- leading to biased estimates and inaccurate variance estimates using these ad hoc strategies that don't account for these mechanisms \citep{buurenFlexibleImputationMissing2018, kang2013, enders2017, austin2021, little2002}. Multiple imputation (MI;~\Citealp{rubin1987}) is proven to be an effective method for dealing with multivariate incomplete data supported by a considerable amount of methodological research \citep{mistlerComparisonJointModel2017, buurenFlexibleImputationMissing2018, enders2017, burgette2010, austin2021, audigier2018, vanbuuren2007, grund2021, hughes2014, little2002}.
% Rubin defined three of such missing data mechanisms: Missing Completely At Random (MCAR) where the cause of the missing data is unrelated to the data, Missing At Random (MAR) where the missing data is related to the observed data, and Missing Not At Random (MNAR) where the missing data may also be related to unobserved data \citep{rubin1976}.

MI separates the missing data problem from the analysis problem \citep{mistlerComparisonJointModel2017, buurenFlexibleImputationMissing2018, enders2017, burgette2010, austin2021, audigier2018, vanbuuren2007, grund2021, hughes2014, little2002, carpenter2013, bartlett2015}. A statistical model specifying the variables and their relationships used for imputation --- i.e. the imputation model --- is defined for every variable with missing values. Each missing value in the dataset is imputed \textit{m} times by drawing values from their posterior predictive distribution conditional on the observed data and parameters from the imputation model. By repeatedly drawing values from the posterior predictive distributions --- in other words, the distribution of plausible replacement values --- the necessary variation associated with the missingness problem is considered. After imputation, each of the imputed datasets are analyzed according to the model of interest, i.e. the substantive analysis model. Then, their corresponding model parameters are pooled together according to Rubin's rules \citep{rubin1987}. 
% \citep{buurenFlexibleImputationMissing2018, austin2021, carpenter2013,enders2017}. 
One central requirement for MI is the concept of congeniality: the imputation model should be at least as general as the analysis model and preferably all-encompassing \citep{grund2018, enders2018, meng1994multiple, bartlett2015, grund2016, little2002}. If not, the imputation model will not be compatible with the analysis model and the pooled estimates of the latter may be biased. 

% So, when the complexity of data increases, specifying the imputation models becomes more difficult \citep{grund2018, buurenFlexibleImputationMissing2018}.
When MI is applied in a multilevel data context, concerns regarding congeniality become more pronounced \citep{mistlerComparisonJointModel2017, enders2018, enders2018a, enders2020, buurenFlexibleImputationMissing2018, taljaard2008, enders2016, resche-rigon2018, audigier2018, dong2023, grund2016, grund2018a, grund2018, ludtke2017, grund2021, quartagno2022}. Multilevel data is hierarchically structured, where, for example, students are nested within classes within schools \citep{hox2017, hox2011}. When analyzing multilevel data, this hierarchical structure should be taken into consideration. Ignoring it will underestimate the intra-class correlation (ICC) --- the proportion of the total variance at the grouping level \citep{gulliford2005, shieh2012, hox2011} --- and standard errors, as conventional statistical analyses assume independence of observations \citep{buurenFlexibleImputationMissing2018, ludtke2017, taljaard2008, hox2011}. Accounting for this structure can be done using multilevel models (MLMs; \Citealp{hox2017, hox2011, ludtke2017}). MLMs can contain variables relating to the individual level --- level-1 variables --- or to the grouping structure --- level-2 variables or potentially higher order structures. For example, imagine a case where students are nested within classes. Here, the academic performance of a student is a level-1 variable, whereas the teacher's experience is a level-2 variable. Additionally, MLMs allow you to specify random intercepts, indicating that some classes have students that significantly perform better or worse academically on average; random slopes, indicating that the relationship between the performance of students and the outcome variable differs between classes; and cross-level interactions, indicating that the effect of performance of students can differ with the teacher's experience \citep{hox2017, hox2011}. Typically, the complexity of the multilevel analysis model is built stepwise with non-linearities: predictors, random intercepts, random slopes, and cross-level interactions are added incrementally to the model. Hence, the analysis model is not determined beforehand \citep{hox2017, hox2011}. Thus, ensuring congeniality for the imputation model can be complex, since the final analysis model is not pre-determined. Furthermore, including the hierarchical structure along with cross-level interactions or other complicated non-linearities in imputation models is quite challenging \citep{buurenFlexibleImputationMissing2018, burgette2010, hox2011}, also because very complex models might not converge \citep{buurenFlexibleImputationMissing2018}.

A popular and flexible implementation of MI in a multilevel context, is fully conditional specification (FCS), otherwise known as chained equations \citep{audigier2018, burgette2010, vanbuuren2007, grund2018a}. FCS employs univariate linear mixed models to account for the hierarchical structure of multilevel models \citep{mistlerComparisonJointModel2017, enders2018, resche-rigon2018} and iteratively imputes each incomplete variable conditional on observed and previously imputed variables \citep{mistlerComparisonJointModel2017, buurenFlexibleImputationMissing2018, enders2016, enders2018, enders2018a, hughes2014, grund2018a}. Furthermore, it can impute non-linearities, such as cross-level interactions, by using ``passive imputation'' or defining a separate imputation model for the non-linearities \citep{buurenFlexibleImputationMissing2018, grund2018}. However, including these non-linearities in FCS is still complicated \citep{grund2021, grund2018,buurenFlexibleImputationMissing2018}. FCS can also handle random intercepts and slopes, yet, once again, correctly specifying an imputation model accounting for these random effects can be challenging \citep{grund2021, grund2018,buurenFlexibleImputationMissing2018}.

%  and, thus, researchers' focus has predominantly been on the inclusion of random intercepts and slopes, but not of cross-level interactions \citep{grund2018a, grund2016, enders2018, enders2018a, enders2020, enders2016}.

Non-parametric, tree-based models might alleviate these complexities when defining imputation models. They do not assume a specific data distribution. So, they implicitly model non-linear relationships and can simultaneously handle continuous and categorical variables \citep{hill2020, burgette2010, lin2019, chipman2010, james2021, salditt2023, breiman1984}. The use of tree-based, non-parametric models like regression trees, random forests, or Bayesian Additive Regression Trees (BART) in imputation of single-level data simplified the imputation process and improved model parameter estimates \citep{burgette2010,xu2016,silva2022,waljee2013}. Specifically, the imputations showed better confidence interval coverage of the parameters, lower variance and lower bias, especially in non-linear or interactive contexts \citep{burgette2010, xu2016, silva2022}. \citet{waljee2013} also found lower misclassification error rate for the predicted class as well as lower imputation error when imputing with a random forest algorithm compared to multivariate imputation by chained equations (\texttt{mice}) using linear, logistic, and polytomous logistic regression imputation models, K-nearest neighbors (KNN) and mean imputation.

Despite these promising findings, BART models have yet to be implemented in a multilevel imputation context. However, in prediction, multilevel-BART (M-BART) models have predominantly been implemented with random intercepts only \citep{chen2020, wagner2020, tan2016, wundervald2022}. \citet{wagner2020} have found that this random intercept R-BART model provided better predictions with a lower mean squared error (MSE) compared to a parametric MLM, \citet{tan2016} found higher area under the curve (AUC) values compared to a single-level BART model and linear logistic random intercept model, and \citet{chen2020} found better predictions and better coverage of the parameter estimates compared to parametric models and a single-level BART model. Other researchers modeled the random intercept as an extra split on each terminal node and found a lower MSE compared to a standard BART model and parametric MLMs \citep{wundervald2022}.~\citet{dorie2022} developed a M-BART model that included random intercepts, random slopes and cross-level interactions by modeling these random parts with a Stan \citep{lee2017} model and the fixed parts with a BART model. Their results showed that their algorithm \texttt{stan4bart} showed better coverage of the sample average treatment effect (SATT) and lower root mean squared error (RMSE) compared to BART models with varying intercept, BART models ignoring the multilevel structure, bayesian causal forests, and parametric MLMs.

% BART models have been implemented in a multilevel prediction context. However, multilevel-BART models (M-BART) have predominantly been implemented with only random intercepts \citep{chen2020, wagner2020, tan2016, wundervald2022}. In a prediction context, 

% \citet{wagner2020} have found that this random intercept M-BART model provided better predictions with a lower mean squared error (MSE) compared to a parametric MLM, \citet{tan2016} found higher area under the curve (AUC) values compared to a single-level BART model and linear random intercept model, and \citet{chen2020} found better predictions and better coverage of the estimates compared to parametric models and a single-level BART model. Other researchers modeled the random intercept as an extra split on each terminal node and found a lower MSE compared to a standard BART model and parametric MLMs \citep{wundervald2022}. 

Considering all these findings, my research question will be: \textit{How can multivariate imputation by chained equations through a multilevel bayesian additive regression trees model improve the bias, variance, and coverage of the multilevel model parameter estimates compared to current practices?} Given the success of non-parametric models in single-level MI, I anticipate that employing M-BART models in a multilevel missing data context will reduce bias, accurately model variance, and improve estimate coverage compared to conventional implementations of multilevel MI, single-level MI, and complete case analysis with the R package \texttt{mice} \citep{buuren2011}. 

\section{Method}
\subsection{Theoretical background}
\subsubsection{Bayesian Additive Regression Trees (BART)} \label{sec:bart}
BART is a sum-of-trees model proposed by \citet{chipman2010} with regression trees as its building blocks \citep{chipman2010, hill2020, james2021}. Regression trees recursively split the data into binary subgroups based on the predictors included in the model. At each step down the tree, the splits are based on the predictor that minimizes the variability within the subgroups. Observations are then assigned to a certain subgroup according to these splits. This is continued until a certain stopping criterion is reached; for example, we desire a minimal number of observations within a subgroup \citep{hastie2017, james2021, salditt2023, breiman1984}. Recursive binary partitioning of the predictor space doesn't assume a specific data form. This makes regression trees, and as a consequence, BART, non-parametric models \citep{hastie2017, james2021, salditt2023, breiman1984}. It allows regression trees to model non-linearities and other complicated relationships well and automatically \citep{hill2020, burgette2010}.
\citet{chipman2010} define the BART model as:
\begin{align}
\label{eq:BART}
f(\textbf{x}) &= \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}),
\end{align} where $f(\mathbf{x})$ is the overall fit of the model: the sum of $K$ regression trees; $\textbf{x}$ are the predictor variables; $T_{k}$ is the k\textsuperscript{th} tree; and $M_{k}$ is the collection of leaf parameters within the k\textsuperscript{th} tree, i.e. the collection of predictions for its terminal nodes \citep{chipman1998, chipman2006, chipman2010, hill2020, james2021}. The data are assumed to arise from a model with additive normally distributed errors: $Y = \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}) + \epsilon, \epsilon \sim \mathcal{N}(0,\,\sigma^{2})$.
Next to the sum-of-trees model, BART also includes a regularization prior that constrains the size and fit of each tree so that each contributes only a small part of the variation in the outcome variables to prevent overfitting. The prior is imposed over all parameters of the sum-of-trees model, specifically, $(T_1, M_1), \dots, (T_K, M_K)$ and $\sigma$. However, the specification of the regularization prior is simplified by a series of independence assumptions: 
\begin{align}
\begin{split}
    \label{eq:independence_prior}
    p((T_1, M_1), \dots, (T_K, M_K), \sigma) &= \Big[\prod_{k}p(T_k, M_k)\Big]p(\sigma), \\
    &= \Big[\prod_{k}p(M_k|T_k)p(T_k)\Big]p(\sigma), \\
    p(M_k|T_k) &= \prod_{j}p(\mu_{jk}|T_k),
\end{split}
\end{align} where $\mu_{jk} \in M_k$. These assumptions state that the tree components ($T_{k}, M_{k}$) and the standard deviation ($\sigma$) are independent of each other, and the leaf parameters within every tree ($\mu_{jk}|T_{k}$) are independent of each other. Thus, priors only need to be specified for those parameters \citep{chipman2010, hill2020, chipman2006, chipman1998}.~\citet{chipman1998} define an independent prior for each tree. The probability that a node splits at depth $d$ is defined as: 
\begin{align}
\label{eq:tree_prior}
    \alpha(1+d)^{-\beta}, \alpha \in (0,1), \beta \in [0, \infty),
\end{align} where the default specification put forth by~\citet{chipman2006,chipman2010} is $\alpha = .95$ and $\beta = 2$. This specification sets the probability of a tree with 1, 2, 3, 4, and 5 nodes at .05, .55, .28, .09, and .03 respectively. Thus, smaller trees are favored.~\citet{chipman2006,chipman2010} also provide a default specification for the prior for the leaf parameters. They propose to rescale the response value to the interval $[-.5,.5]$ and then, the leaf parameter prior is defined as: 
\begin{align}
\label{eq:leaf_prior}
    \mu_{jk} \sim \mathcal{N}(0, \sigma^2_{\mu}), \text{with } \sigma^2_{\mu} = \frac{.5}{t\sqrt{K}},
\end{align} where $t$ is a preselected number and $K$ is the number of trees. This prior shrinks the tree parameters $\mu_{jk}$ towards 0, decreasing the effect of the individual tree components. If $t$ or $K$ increases, more shrinkage is applied.~\citet{chipman2006,chipman2010} recommend using $t = 2$ --- or values between 1 and 3 --- as a default. Furthermore, \citet{chipman2006,chipman2010} propose the conjugate inverse chi-square distribution as the prior for the residual standard deviation --- $\sigma^2 \sim \nu\lambda/\chi^{2}_{\nu}$. They represent $\lambda$, the degrees of freedom, as the probability that $\sigma$ --- from BART ---, is less than the estimated residual standard deviation from a linear regression model, $\hat{\sigma}_\text{OLS}$. Their default specification is $\nu = 3$ and $\text{Pr}(\sigma < \hat{\sigma}_\text{OLS}) = \lambda = .9$ \citep{chipman2010, hill2020, chipman2006, chipman1998}.

BARTs are estimated using the Bayesian back-fitting Markov Chain Monte Carlo (MCMC) algorithm with a Metropolis-within-Gibbs sampler \citep{chipman2010, hill2020, chipman2006, chipman1998,james2021}. Each tree is initialized with the mean response value divided by the number of trees as its root node --- $\hat{f}^1_k(x) = \frac{1}{nK}\sum_{i = 1}^{n}y_i$, with sample size $n$. Then, each pair $(T_k, M_k)$ is updated considering the remaining trees, their associated parameters, and $\sigma$ by sampling from the following conditional distribution: 
\begin{align}
\label{eq:backfitting}
    (T_k, M_k)|T_{k'}, M_{k'}, \sigma, y,
\end{align} where, $T_{k'}$ is every tree expect the k\textsuperscript{th} tree. This conditional distribution only depends on ($T_{k'}, M_{k'}, y$) through the partial residuals:
\begin{align}
    \label{eq:partialresiduals}
    r_i &= y_i - \sum_{k' < k} \hat{f}^{b}_{k'}(x_{i}) - \sum_{k' > k} \hat{f}^{b-1}_{k'}(x_{i}), \text{with } i = 1, \dots, n,
    \end{align} where $\hat{f}^{b}_{k}(x_{i})$ is the prediction of the $k$\textsuperscript{th} tree in the $b$\textsuperscript{th} iteration for person $i$ and sample size $n$. Thus, updating each pair $(T_k, M_k)$ simplifies to proposing a new tree fit to the partial residuals, $r_{i}$, treating them as the data, by perturbing the tree from the previous iteration. Perturbations entail either \textit{growing}, \textit{pruning}, or \textit{changing} a tree.~\textit{Growing} means adding additional splits, \textit{pruning} removes splits, and \textit{changing} changes decision rules. The algorithm stops after the specified number of iterations \citep{chipman2010, hill2020, chipman2006, chipman1998, james2021}.

\subsubsection{Random intercept BART (R-BART)}
\citet{wagner2020,tan2016} and \citet{dorie2024} define an R-BART model including a random intercept. The BART model (\ref{eq:BART}) is extended to include a random intercept by: 
\begin{align} 
    \label{eq:R-BART}
    f(\textbf{x}) &= \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}) + \alpha_{j}, 
\end{align} where, now, $f(\textbf{x})$ is the overall fit of the model incorporating random intercept $\alpha_{j}$ for cluster $j$. So, the data are now assumed to arise from the following model: 
\begin{align}
    \label{eq:R-BART_model}
    Y_{ij} = \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}) + \alpha_j + \epsilon_{ij}, & &\epsilon_{ij} \sim \mathcal{N}(0,\,\sigma^{2}), \hspace{.2cm} \alpha_{j} \sim \mathcal{N}(0,\,\tau^{2}),
\end{align} where $\alpha_j \perp \epsilon_{ij}$. Now the joint prior distribution (\ref{eq:independence_prior}) becomes: 
\begin{align}
\begin{split}
    \label{eq:indepdence_prior_rbart}
    p((T_1, M_1), \dots, (T_K, M_K), \sigma) &= \Big[\prod_{k}p(T_k, M_k)\Big]p(\sigma)p(\tau), \\
    &= \Big[\prod_{k}p(M_k|T_k)p(T_k)\Big]p(\sigma)p(\tau), \\
    p(M_k|T_k) &= \prod_{j}p(\mu_{jk}|T_k).
\end{split}
\end{align} 
A Metropolis-within-Gibbs algorithm is used to draw values from the posterior. First, the Gibbs sample for $\sigma$, $\tau$, and $\alpha_j$ are obtained from their respective posterior distributions. Then, we obtain $\tilde{Y}_{ij} = Y_{ij} - \alpha_{j}$ and view $\tilde{Y}_{ij}| \boldsymbol{x}_{j}$ as a BART model. So, $\tilde{Y}$ is now used as the outcome variable in the BART algorithm described in the previous section,~\ref{sec:bart}.~\citep{wagner2020,tan2016}.~\citet{dorie2024} implemented this algorithm within the R package \texttt{dbarts} with the function \texttt{rbart\_vi()}. Where, the default prior for the random intercept is $\tau \sim \text{Cauchy}(0, 2.5)$: a Cauchy distribution with a scale parameter 2.5 times the original scale.

\subsubsection{stan4bart}

\citet{dorie2022} developed a M-BART model that included random intercepts, random slopes, and cross-level interactions. They extend a Bayesian linear mixed model with a BART model (\ref{eq:BART}):
\begin{align}
    \label{eq:stan4bart}
    f(\textbf{x}) &= \boldsymbol{\beta}\mathbf{x}^{\beta} + \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}) + \boldsymbol{\lambda}\mathbf{w},
\end{align} where $\boldsymbol{\beta}$ is a vector of linear, parametric coefficients; $\mathbf{x}^{\beta}$ the design matrix for the linear predictors; $\boldsymbol{\lambda}$ a vector of the parametric random effects; $\mathbf{w}$ the design matrix for the random effects; and $\sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k})$ is a non-parametric, sum-of-trees BART model \citep{dorie2022}. So, the data are assumed to arise from the following model:
\begin{align}
    \label{eq:stan4bart_model}
    Y_{ij} = \boldsymbol{\beta}\mathbf{x}^{\beta} + \sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k}) + \boldsymbol{\lambda}\mathbf{w} + \epsilon_{ij}, & &\epsilon_{ij} \sim \mathcal{N}(0,\,\sigma^{2}), \hspace{.2cm} \boldsymbol{\lambda} \sim \mathcal{N}(0,\,\boldsymbol{\Sigma}_{\lambda}),
\end{align} where $\boldsymbol{\Sigma}_{\lambda}$ is the variance-covariance matrix for the random intercept and slopes. The model is implemented as a Gibbs sampler: a  Hamiltonian Monte Carlo, no-U-turn sampler with a diagonal Euclidean adaptation matrix is used to jointly sample the linear, parametric components given the non-parametric components. The non-parametric components are sampled using the BART algorithm described in section~\ref{sec:bart}. To accomplish this, a parametric Stan model \citep{lee2017} fits equation \ref{eq:stan4bart} with $\sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k})$ as a generic linear offset. \citet{dorie2022} combine a custom mutable Stan sampler object with a BART sampler with a fixed variance and offset term. First, the Stan sampler collects the current draws of the BART model into $vec_i\sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k})$ and uses this to draw $\mathbf{\beta}, \mathbf{\lambda}, \sigma, \Sigma_\lambda | \mathbf{Y}, vec_i\sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k})$. Then, $\sigma$ and $vec_i\big[\boldsymbol{\beta}\mathbf{x}_i^{\beta} + \boldsymbol{\lambda}\mathbf{w}_i\big]$ are passed to BART, which produces $M_k,T_k | \mathbf{Y}, vec_i\big[\boldsymbol{\beta}\mathbf{x}_i^{\beta} + \boldsymbol{\lambda}\mathbf{w}_i\big], \sigma, M_{k'}, T_{k'}$. The cycle is completed by passing $vec_i\sum^{K}_{k=1}g(\textbf{x}; T_{k}, M_{k})$ back to Stan. The process is continued for the set number of posterior samples which are intended for inference. This algorithm is implemented in the R package \texttt{stan4bart} \citep{dorie2023a}.

\subsection{Simulation study}
\subsubsection{Data generating mechanism}
A simulation study is assembled to evaluate the performance of M-BART models in a multilevel imputation context. The population data-generating mechanism is based on the following MLM:
\begin{subequations}
\label{eq:population}
\begin{align}
        y_{ij} &= \beta_{0j} + \sum_{f=1}^{7}\beta_{fj}X_{fij} + \epsilon_{ij}, \hspace{3cm} X_{fij} \sim \mathcal{MVN}(0, \boldsymbol{\Sigma}_{x}), \label{eq:population1} \\
        &\hspace{.5cm}\beta_{0j} = \gamma_{00} + \sum_{q=1}^{2}\gamma_{0p}Z_{pj} + \upsilon_{0j}, \label{eq:beta0}\\
        &\hspace{.5cm}\beta_{fj} = \gamma_{f0} + \sum_{q=1}^{2}\gamma_{fp}Z_{pj} + \upsilon_{fj}, \hspace{2cm} Z_{pj} \sim \mathcal{MVN}(0, \boldsymbol{\Sigma}_{z}), \label{eq:betaf}
\end{align}
\end{subequations} where $y_{ij}$ is a continuous level-1 outcome variable for person $i$ in group $j$ and $X_{fij}$ are 7 continuous level-1 variables and $Z_{pj}$ are 2 continuous level-2 variables. The predictors are multivariate normally distributed with means of 0 and variance-covariance matrix $\boldsymbol{\Sigma}_{x}$ and $\boldsymbol{\Sigma}_{z}$, respectively:
\begin{subequations}
\begin{align}
    \boldsymbol{\Sigma}_{x} &= \begin{pmatrix}
        6.25& & & & & & \\
        2.25& 9& & & & & \\
        1.5& 1.8& 4& & & & \\
        2.25& 3.06& 2.04& 11.56& & & \\
        1.5& 1.8& 1.2& 2.04& 4& & \\
        1.125& 1.35& 0.9& 1.53& .9& 2.25& \\
        3.3& 3.96& 2.64& 4.488& 2.64& 1.98& 19.36
    \end{pmatrix}, \label{eq:sigma.x} \\
    \boldsymbol{\Sigma}_{z} &= \begin{pmatrix}
        1& \\
        .48& 2.56
    \end{pmatrix}. \label{eq:sigma.z}
\end{align}
\end{subequations}
The covariances between the variables are calculated such that the correlation between the variables is .3, aligned with Cohen's \citeyearpar{cohen1990} medium effect size benchmark. The residuals are normally distributed as,
\begin{align}
    \epsilon_{ij} \sim \mathcal{N}(0, 25).
\end{align}
The random intercept $\beta_{0j}$ is determined by the overall intercept $\gamma_{00}$, the 2 group-level effects $\gamma_{0p}Z_{pj}$ and the group-level random residuals $\upsilon_{0j}$. The overall intercept $\gamma_{00}$ is set to 10 and the group-level effects $\gamma_{01}$ and $\gamma_{02}$ to .5.
The 7 regression coefficients $\beta_{fj}$ for the continuous variables $X_{fij}$ depend on the intercepts $\gamma_{f0}$, the cross-level interactions $\gamma_{fp}Z_{pj}$, and the random slopes $\upsilon_{fj}$. The 7 intercepts, or within-group effect sizes, $\gamma_{f0}$ are set to .5, the cross-level interactions $\gamma_{11}$, $\gamma_{21}$, and $\gamma_{32}$ are set to .35.
\begin{align}
    \gamma_{00} = 10, \hspace{.2cm} \boldsymbol{\gamma}_{0p} = \begin{pmatrix}
        .5 \\ .5
        \end{pmatrix}, \hspace{.2cm} \boldsymbol{\gamma}_{f0} = \begin{pmatrix}
        .5 \\ .5 \\ .5 \\ .5 \\ .5 \\ .5 \\ .5
        \end{pmatrix}, \hspace{.2cm} \boldsymbol{\gamma}_{fp} = \begin{pmatrix}
        .35 & 0 \\ .35 & 0 \\ 0 & .35 \\ 0 & 0 \\ 0 & 0 \\ 0 & 0 \\ 0 & 0
        \end{pmatrix}.
\end{align}
The random slopes are multivariate normally distributed with a mean of 0 and a variance-covariance matrix $\mathbf{T}$ shown in equation~\ref{eq:T}. Again, the covariances are calculated to yield a correlation of .3.
\begin{align}
    \boldsymbol{\upsilon}_{j} \sim \mathcal{MVN}(0, \mathbf{T}), \hspace{.2cm}
    \mathbf{T} = \begin{pmatrix}
        t_{00}& & & & & & \\
          .3& 1& & & & & \\
          .3& .3& 1& & & & \\
          .3& .3& .3& 1& & & \\
          0& 0& 0& 0& 0& & \\
          0& 0& 0& 0& 0& 0& \\
          0& 0& 0& 0& 0& 0& 0 \\
          0& 0& 0& 0& 0& 0& 0& 0
    \end{pmatrix} \label{eq:T}.
\end{align}
The variance of $\upsilon_{0j}$, the group-level random residuals $t_{00}$, are scaled such that the ICC was .5. The following formula is used to calculate $\upsilon_{0j}$ following the variance decomposition from~\cite{rights2019}:

\begin{align}
\label{eq:variancedecomposition}
\text{ICC} = \frac{\boldsymbol{\gamma}^{b'}\boldsymbol{\phi}^{b}\boldsymbol{\gamma}^{b} + \tau_{00}}{\boldsymbol{\gamma}^{w'}\boldsymbol{\phi}^{w}\boldsymbol{\gamma}^{w} + \boldsymbol{\gamma}^{b'}\boldsymbol{\phi}^{b}\boldsymbol{\gamma}^{b} + tr(\mathbf{T}\boldsymbol{\Sigma})+ \tau_{00} + \sigma^{2}},
\end{align} where $\boldsymbol{\gamma}^{b}$ and $\boldsymbol{\gamma}^{w}$ are the level-1 and level-2 fixed effects; $\boldsymbol{\phi}^{b}$ is the variance-covariance matrix of a vector with 1 --- for the intercept --- and all level-2 predictors; $\boldsymbol{\phi}^{w}$ is the variance-covariance matrices of all cluster-mean-centered level-1 predictors; $\tau_{00}$ is the variance of the random intercept; $\mathbf{T}$ is the variance-covariance matrix of the random intercept and slopes; $\boldsymbol{\Sigma}$ is the variance-covariance matrix of a vector containing 1 --- for the intercept --- and the level-1 variables; and $\sigma^{2}$ is the residual variance. The value for $\tau_{00}$ is calculated using the function \texttt{uniroot()} in R (R version 4.3.2 (2023-10-31); \Citealp{rcoreteam2023}).

\subsubsection{Simulation design} \label{sec:simulation}
Table~\ref{tab:simulationparameters} shows the design factors considered in the simulation study. These factors are either grounded in prior research or deemed realistic in real-world applications \citep{gulliford1999, murray2003, hox2017, grund2018, enders2018a, enders2020}. According to \citet{kreft2007}, 30 groups is the smallest acceptable number in multilevel research and 50 groups is frequent in organizational research \citep{maas2005}. 
\begin{wraptable}{r}{.55\textwidth}
    \centering
    \caption{Simulation design}
    \label{tab:simulationparameters}
    \begin{tabular}{l|c}
            \textbf{Design factors}                             & \textbf{Values} \\ \hline
            Number of clusters (J))                             & 30, 50 \\
            Within-cluster sample size (n\textsubscript{j})     & 15, 50 \\
            Intraclass Correlation (ICC)                        & .5 \\
            Missing data mechanism                              & MCAR, MAR \\
            Amount of missingness                               & 0\%, 50\%
    \end{tabular}
\end{wraptable} Group sizes of 15 are typical in educational research \citep{ludtke2017} and group sizes of 50 and an ICC of .5 are often used in simulation studies \citep{maas2005,enders2018,akkayahocagil2023,grund2018,enders2018a,enders2020,salditt2023,mistler2017}.~\citet{oberman2023} recommend including both Missing Completely At Random (MCAR) and Missing At Random (MAR) missingness mechanisms in simulation studies. The statistical properties of the imputation method are not deemed sound if it cannot yield valid inferences under MCAR and including MAR is important in evaluating the imputation method's performance. The amount of missingness in datasets is varied between 0\% --- as an additional benchmark --- and 50\%, which is often used in simulation studies as a high amount of missingness \citep{ludtke2017,grund2016,schouten2021}. 5 different imputation methods are compared: 
\begin{enumerate}
    \item conventional single-level imputation with PMM (predictive mean matching),
    \item conventional multilevel imputation with PMM,
    \item single-level BART imputation,
    \item M-BART imputation accounting for random intercepts \citep{wagner2020, tan2016},
    \item M-BART imputation accounting for random effects and cross-level interactions \citep{dorie2022}.
\end{enumerate} 
For each combination of design factors, 100 datasets are simulated for the first 4 methods. A differing number of datasets are simulated for the 5\textsuperscript{th} method due to time restrictions, which can be seen in table \ref{tab:stan4bartsimulations}.
  
The first and second methods are implemented with the method \texttt{pmm} from \texttt{mice} and \texttt{2l.pmm} in combination with \texttt{2lonly.mean} --- for the level-1 and level-2 variables --- from \texttt{miceadds} \citep{robitzsch2024} respectively.

The third, fourth, and fifth methods are implemented by writing new method-functions in R for the package \texttt{mice}. The functions \texttt{bart()} and \texttt{rbart\_vi()} from the \texttt{dbarts} package were used for the third and fourth methods \citep{dorie2024}. The function \texttt{stan4bart()} from the package \texttt{stan4bart} was used for the fifth method \citep{dorie2023a}. The functions were written such that they can be used as imputation methods in the \texttt{mice} package as follows: for every variable to be imputed, a respective BART model is fitted --- with the default specifications from the \texttt{bart} function --- based on the predictor matrix. Then, the fitted values --- the posterior means --- are extracted for the observed and missing values. Imputations for the missing values are then obtained using predictive mean matching: a set of candidate donors are obtained by matching the predicted values for the observed cases that are closest to the predicted values for the missing cases --- i.e. type 0 matching \citep{buurenFlexibleImputationMissing2018}. Then, the observed value of one randomly selected donor is used as the imputed value for the missing case. The code for these functions can be found in \ref{appendix:imputationfunctions}.

\begin{wraptable}{r}{.7\textwidth}
    \centering
    \caption{Number of simulated datasets used in evaluation of the stan4bart imputation method for every design factor.}
    \label{tab:stan4bartsimulations}
    \resizebox{\linewidth}{!}{%
    \begin{tabular}{>{\hspace{0pt}}m{0.215\linewidth}|>{\hspace{0pt}}m{0.215\linewidth}|>{\hspace{0pt}}m{0.215\linewidth}|>{\hspace{0pt}}m{0.215\linewidth}|>{\hspace{0pt}}m{0.215\linewidth}}
     & \textbf{Number of groups: 50 }\par{}\textbf{Group size: 15} & \textbf{Number of groups: 30}\par{}\textbf{Group size: 50} & \textbf{Number of groups: 50}\par{}\textbf{Group size: 15} & \textbf{Number of groups: 50}\par{}\textbf{Group size: 50} \\ 
    \hline
    \textbf{MAR} & 20 & 20 & 20 & 20 \\
    \textbf{MCAR} & 100 & 40 & 100 & 20
    \end{tabular}
    }
    \end{wraptable}

For all imputation methods, the incomplete datasets are imputed 5 times with 10 iterations each. Then, each of the 5 imputed datasets are analyzed using the R package \texttt{lme4} \citep{bates2015} with an MLM reflecting the population generating mechanism. The estimates from the 5 imputed datasets are pooled together using the R package \texttt{mice} \citep{buuren2011}. These pooled estimates are compared on the bias, coverage, and the width of the 95\% confidence intervals.

As an additional benchmark, the imputation methods are compared to analyses using listwise deletion --- i.e. complete case analysis --- and using the true data without missing values --- i.e. the comparative truth.

\subsubsection{Missing data generation}
Missing values in the variables are introduced by multivariate amputation using the function \texttt{ampute()} \citep{schouten2018} from package \texttt{mice}. As can be seen in table~\ref{tab:simulationparameters}, the missing data mechanism is either Missing Completely At Random (MCAR) or Missing At Random (MAR). The missing data mechanism is said to be MCAR when the cause of the missing data is unrelated to the data and MAR when the missing data is related to the observed data \citep{rubin1976}. The amount of missingness is either 0\% or 50\%, which is defined as the percentage of cases that have at least one missing value. 

For both MCAR and MAR, all possible patterns with 1 to 5 missing values out of the 10 variables (\textit{x1, x2, x3, x4, x5, x6, x7, z1, z2, and y}) per case are generated. They have the same relative frequency of occurrence in the datasets. %So, 50\% of the cases had 1 to 5 missing values. 

For the MAR mechanism, the weighted sum of scores on the observed variables is used to predict the probability of missingness for a case. When they remain observed in a specific pattern, the weights of the variables \textit{x4} and \textit{z1} are set to 2 and 1.5 and the weights of the other variables are set to 1. The type of missingness is set to \texttt{`RIGHT'} meaning that cases with a higher weighted sum of scores have a higher probability of becoming incomplete. So, this means that cases with higher values on \textit{x4} and \textit{z1} are more likely to become incomplete.

In summary, either no missing values are introduced (0\%), or up to 5 missing values are introduced in 50\% of the cases. When data is MAR, the probability of a value being missing depends on the observed values of all other variables, with variables \textit{x4} and \textit{z1} having a greater influence on this probability.

\subsubsection{Evaluation}
The estimates from the analysis models are evaluated in terms of absolute bias, coverage of 95\% confidence intervals, with their respective Monte Carlo SE (MCSE), and the width of the 95\% confidence intervals \citep{morris2019,oberman2023}:
\begin{align}
    \text{Bias} &= \frac{1}{n_{\text{sim}}} \sum_{t=1}^{n_{\text{sim}}} (\hat{\theta}_t - \theta), &
    \text{MCSE}_{\text{Bias}} &= \sqrt{\frac{\sum_{t=1}^{n_{\text{sim}}} (\hat{\theta}_t - \bar{\theta})^2}{n_{\text{sim}}(n_{\text{sim}}-1)}}, \label{eq:bias} \\
    % \text{MSE} &= \frac{1}{n_{\text{sim}}} \sum_{t=1}^{n_{\text{sim}}} (\hat{\theta}_t - \theta)^{2}, &
    % \text{MCSE}_{\text{MSE}} &= \sqrt{\frac{\sum_{t=1}^{n_{\text{sim}}} [(\hat{\theta}_t - \theta)^2 - \hat{\text{MSE}}]^2}{n_{\text{sim}}(n_{\text{sim}}-1)}}, \label{eq:mse}\\
    \text{Coverage} &= \frac{1}{n_{\text{sim}}} \sum_{t=1}^{n_{\text{sim}}} 1(\hat{\theta}_{\text{low,i}} \leq \theta \leq \hat{\theta}_{\text{upp,i}}), &
    \text{MCSE}_{\text{Coverage}} &= \sqrt{\frac{\hat{\text{Coverage}}(1-\hat{\text{Coverage}})}{n_{\text{sim}}}}, \label{eq:coverage} \\
    \text{CIW} &= \frac{1}{n_{\text{sim}}} \sum_{t=1}^{n_{\text{sim}}} (\hat{\theta}_{\text{upp,i}} - \hat{\theta}_{\text{low,i}}), \label{eq:width}
\end{align} where $\hat{\theta}_t$ is the estimated parameter in simulation \textit{t}, $\theta$ is the true value, $\bar{\theta}$ is the mean of $\hat{\theta}_t$, and $n_{\text{sim}}$ is the number of simulated datasets. The lower and upper bounds of the 95\% confidence intervals are denoted as $\hat{\theta}_{\text{low,i}}$ and $\hat{\theta}_{\text{upp,i}}$ respectively. The coverage is the proportion of the 95\% confidence intervals that contain the true value. 

Published simulation studies frequently consider a relative bias --- which is the absolute bias divided by the true parameter value multiplied by 100 --- of 10\% as acceptable bias \citep{enders2018,enders2018a,enders2020,finch1997}. \citet{morris2019,enders2018,oberman2023,buurenFlexibleImputationMissing2018} suggest that a coverage of 95\% is acceptable. Poor coverage, i.e. below 95\%, indicates biased estimates or too narrow intervals. While, coverage above 95\% indicates that efficiency could still be gained. Furthermore, \citet{bradley1978} suggests a liberal criterion for coverage between 92.5\% and 97.5\% being acceptable \citep{enders2018,enders2018a,enders2020}. In this study coverage is only considered for the fixed effects, since literature suggests that symmetric confidence intervals for the random parts is unsuitable \citep{enders2018,enders2018a,enders2020,maas2005}.
The width of the confidence intervals is a measure of the statistical precision of the estimates: a smaller width indicates a more precise estimate \citep{oberman2023,buurenFlexibleImputationMissing2018}.

\section{Results}
\graphicspath{{./graphs/}}
\subsection{Bias}
Figures \ref{fig:biasinterceptlevel1} through \ref{fig:random2} show the absolute bias and corresponding Monte Carlo SE for the estimates of the linear mixed model for all imputation methods in consideration: the overall intercept --- $\gamma_{00}$; the level-1 effects --- $\gamma_{10}, \gamma_{20},\dots,\gamma_{70}$; the level-2 effects --- $\gamma_{01}$ and $\gamma_{02}$; cross-level interactions --- $\gamma_{11}, \gamma_{21}$, and $\gamma_{32}$; the random slopes --- $\upsilon_{1}, \upsilon_{2}$, and $\upsilon_{3}$; and the residual and intercept variance --- $\upsilon{0}$ and $\epsilon_{ij}$.

Figure \ref{fig:biasintercept} shows that for most imputation methods when the data is MAR, the overall intercept is approximately unbiased when there are 30 groups --- the absolute biases fall between the 10\% relative bias lines --- but is underestimated when there are 50 groups. stan4bart is unbiased with the smallest sample size and overestimates the intercept when there are larger groups. Nonetheless, the simulation uncertainty for stan4bart still encompasses the zero-bias line. Listwise deletion underestimates the intercept compared to the 0\% missing, ``true'' data when the data is MAR.  
When the data is MCAR, there seem to be fewer differences in performance between the imputation methods: all approximately overestimate the intercept with 30 groups of size 15 and are approximately unbiased with the other group conditions, except for stan4bart, which overestimates the intercept with 50 groups of size 50. 

Figure \ref{fig:biaslevel1} shows the absolute bias of the level-1 effects --- $\gamma_{10}, \gamma_{20},\dots,\gamma_{70}$. When the sample size is smallest --- i.e. 30 groups of size 15 --- fluctuations in bias are frequent for all methods when the data is MAR and MCAR. 2l.pmm, pmm, and bart seem to perform best out of all imputation methods for both missingness mechanisms, especially with a larger total sample size. stan4bart seems to overestimate some fixed effects, which increases with the total sample size and when the data is MAR. Overall, rbart has the worst performance in terms of absolute bias, consistently underestimating some level-1 effects.

\begin{figure}[H]
    \centering 
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{biasintercept.png}
        \caption{Overall intercept}
        \label{fig:biasintercept}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \centering 
        \includegraphics[width=1\textwidth]{biaslevel1.png}
        \caption{Level-1 effects}
        \label{fig:biaslevel1}
    \end{subfigure}
    \caption{Absolute bias of the overall intercept and level-1 fixed effects of the linear mixed model with respective Monte Carlo SE for all simulated datasets over 100 simulations with ICC = .5. The dashed lines represent ±10\% relative bias. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}.}
    \label{fig:biasinterceptlevel1}
\end{figure}
Considering the level-2 effects --- $\gamma_{01}$ and $\gamma_{02}$ --- from figure \ref{fig:biaslevel2}, stan4bart performs the worst out of all imputation methods: underestimating the level-2 effects. 2l.pmm performs best out of all imputation methods, even though still over- or underestimating the level-2 effects at times and seemingly performing slightly worse under MCAR. pmm and rbart consistently underestimate the level-2 effects for all conditions. bart performs slightly better, at times even mimicking the performance of 2l.pmm. 

For the cross-level interactions --- $\gamma_{11}, \gamma_{21}$, and $\gamma_{32}$ ---, stan4bart performs worst out of all methods. Figure \ref{fig:biascrosslevel} shows that stan4bart consistently underestimates the cross-level interactions. For both MAR and MCAR, listwise deletion performs largely acceptable in terms of bias. 2l.pmm performs best out overall, nonetheless still underestimating the cross-level interactions regularly. Furthermore, 2l.pmm performs slightly better under MCAR than MAR. bart outperforms pmm and rbart, but still underestimates the cross-level interactions. Additionally, bart, rbart and pmm perform worse with larger groups. 

\begin{figure}[H]
    \centering 
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{biaslevel2.png}
        \caption{Level-2 effects}
        \label{fig:biaslevel2}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{biascrosslevel.png}
        \caption{Cross-level interactions}
        \label{fig:biascrosslevel}
    \end{subfigure}
    \caption{Absolute bias of the fixed level-2 effects and cross-level interactions of the linear mixed model with respective Monte Carlo SE for all simulated datasets over 100 simulations with ICC = .5. The dashed lines represent ±10\% relative bias. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}.}
    \label{fig:biaslevel2crosslevel}
\end{figure}

The absolute bias for the random  --- $\upsilon_1$ to $\upsilon_3$ --- in figure \ref{fig:biasrandom} show that stan4bart performs best overall. When the data is MAR, stan4bart provides acceptable biases when group sizes are 15 performing better with more but smaller groups. pmm, bart and rbart perform worst: consistently underestimating the random slopes for all factor conditions. 2l.pmm performs better than pmm, bart, and rbart, but still underestimates the random slopes for most conditions. Listwise deletion performs largely acceptable in terms of bias, most of the time staying within the 10\% relative bias lines for both MAR and MCAR.
From figure \ref{fig:bias2} it can be seen that stan4bart and 2l.pmm have an acceptable bias for the intercept variance for most conditions. stan4bart seems to slightly overestimate the intercept variance when the data is MAR compared to MCAR. Additionally, stan4bart improves in bias when there are more groups in the dataset. 2l.pmm slightly underestimates the intercept variance to an acceptable extent for all conditions. pmm, rbart and bart routinely underestimate the intercept variance overall. Listwise deletion shows a very minor bias, underestimating the intercept variance when the data is MAR. 

Looking at the residual variance, listwise deletion is the only method that is approximately unbiased for all --- or any --- condition. All other imputation methods routinely overestimate the residual variance. stan4bart has the best performance followed by 2l.pmm, bart, pmm, and rbart, in that order. Overall, the bias seems consistent across all conditions. Aside from stan4bart that increases in bias when the total sample size increases and 2l.pmm which decreases in bias with more groups. 

\begin{figure}[H]
    \centering 
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{biasrandom.png}
        \caption{Random slopes}
        \label{fig:biasrandom}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{bias2.png}
        \caption{$\epsilon_{ij}$ and $\upsilon_0$}
        \label{fig:bias2}
    \end{subfigure}
    \caption{Absolute bias of the random effects of the linear mixed model with respective Monte Carlo SE for all simulated datasets over 100 simulations with ICC = .5. The dashed lines represent ±10\% relative bias. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}.}
    \label{fig:biasrandom2}
\end{figure}

\subsection{Coverage}
Figures \ref{fig:coveragelevel1} and \ref{fig:coveragelevel2} show the coverage of the 95\% confidence intervals of the fixed effects --- the overall intercept, level-1 effects, level-2 effects, and cross-level interactions --- of the linear mixed model for all imputation methods in consideration with corresponding Monte Carlo SE.

Figure \ref{fig:coveragelevel1} shows that the coverage of the overall intercept, $\gamma_{00}$, is best for imputation method 2l.pmm when the data is MAR. However, when the data is MCAR, stan4bart performs best. 2l.pmm shows undercoverage in the smallest sample size when the data is MCAR and stan4bart shows fluctuations in coverage when the data is MAR. pmm and rbart show undercoverage for most conditions. bart undercovers the intercept for all conditions unless the data is MCAR with 50 groups.

Next, the coverage of the level-1 effects in figure \ref{fig:coveragelevel1} shows that 2l.pmm performs best. stan4bart and pmm also show a good performance in terms of coverage, however, they regularly overcover and sometimes undercover the level-1 effects. bart shows undercoverage more consistently. rbart has most fluctuations in coverage: when group sizes are 50, it shows undercoverage as low as around 47,5\% and overcoverage as high as around 98\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{coveragelevel1.png}
    \caption{Coverage of the 95\% confidence intervals of the intercept and level-1 effects of the linear mixed model with respective Monte Carlo SE for all simulated datasets over 100 simulations with ICC = .5. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}. The solid line represents the nominal 95\% coverage, and the dashed lines at .925 and .975 represent the liberal criterion from \citet{bradley1978}.}
    \label{fig:coveragelevel1}
\end{figure}

Lastly, the coverage of the level-2 effects and cross-level interactions in figure \ref{fig:coveragelevel2} shows that bart has the overall worst coverage, with coverages ranging from 65\% to 82.5\%. pmm also routinely undercovers the level-2 effects, which worsens with group sizes of 50. rbart tends to overcover the level-2 effects, but also undercovers them at times. Overall, 2l.pmm demonstrates the best coverage, despite exhibiting slight undercoverage when the data is MAR and there are 50 groups. stan4bart shows under- and overcoverage for the level-2 effects, but performs better with smaller groups and when the data is MCAR.

2l.pmm also has the best coverage of the cross-level interactions. Albeit showing under- or overcoverage at times. Listwise deletion also performs considerably good, showing better coverage when the data is MAR compared to MCAR. When the group size is 15, pmm; bart; and rbart, show an acceptable coverage --- sometimes slightly under- or overcovering the cross-level interactions ---, but considerable undercoverage when the group size is increased to 50. stan4bart has the worst coverage of the cross-level interactions: showing considerable undercoverage, especially when the group size is increased to 50.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{coveragelevel2.png}
    \caption{Coverage of the 95\% confidence intervals of the level-2 and cross-level effects of the linear mixed model with respective Monte Carlo SE for all simulated datasets over 100 simulations with ICC = .5. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}. The solid line represents the nominal 95\% coverage, and the dashed lines at .925 and .975 represent the liberal criterion from \citet{bradley1978}.}
    \label{fig:coveragelevel2}
\end{figure}

\subsection{Confidence interval width}
Figures \ref{fig:ciwinterceptlevel1} and \ref{fig:ciwlevel2crosslevel} show the 95\% confidence interval width (CIW) of the estimates of the fixed effects for all imputation methods in consideration.

Figure \ref{fig:ciwintercept} shows that the CIW of the intercept is smallest for pmm. However, paired with the coverage estimates from figure \ref{fig:coveragelevel1}, pmm seems to be efficient but routinely undercovers the intercept. The same pattern can be seen for bart and rbart: showing smaller confidence intervals widths, they routinely undercover the intercept. 2l.pmm, stan4bart and listwise deletion show larger CIWs --- somewhat mimicking the true data --- oft paired with acceptable coverage.

For the level-1 effects, $\gamma_{10}, \gamma_{20},\dots,\gamma_{70}$, the CIW of the true data is oft smallest. Listwise deletion and stan4bart are closest in mimicking the width of the true data paired with acceptable coverages in figure \ref{fig:coveragelevel1}. 2l.pmm and bart have overall slightly larger confidence intervals, and, as mentioned before, 2l.pmm has the best coverage of the level-1 effects while bart shows more undercoverage. pmm and rbart show the largest confidence intervals. pmm shows both under- and overcoverage in figure \ref{fig:coveragelevel1}. While rbart shows considerable undercoverage when its confidence intervals are smallest and overcoverage when its confidence intervals are largest --- for example for effect $\gamma_{70}$ and $\gamma_{60}$ when the data is MAR with 50 groups of 50. Lastly, the CIW for all methods decreases with an increase in total sample size. 

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{ciwintercept.png}
        \caption{Overall intercept}
        \label{fig:ciwintercept}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{ciwlevel1.png}
        \caption{Level-1 effects}
        \label{fig:ciwlevel1}
    \end{subfigure}
    \caption{Width of the 95\% confidence intervals for the intercept and level-1 effects of the linear mixed model for all simulated datasets over 100 simulations with ICC = .5. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}.}
    \label{fig:ciwinterceptlevel1}
\end{figure}

From figure \ref{fig:ciwlevel2} we can see that 2l.pmm and listwise deletion have largest CIWs for the level-2 effects, mimicking the true data. The other imputation methods, pmm; bart; rbart; and stan4bart, show smaller confidence intervals that decrease when the total sample size increases, leading to more undercoverage --- as can be seen in figure \ref{fig:coveragelevel2}. At the same time, 2l.pmm and listwise deletion show a decrease in width when there are more groups in the data, which is a pattern mirrored by the true data as well. 

The width of the 95\% confidence intervals for the cross-level interactions --- shown in figure \ref{fig:ciwcrosslevel} show a similar pattern for all methods: when group sizes are 15, all methods have confidence intervals larger than the true data. However, when group sizes are 50, the confidence intervals decrease in size for all methods, either being smaller than or similar to the true data. This pattern is also reflected in figure \ref{fig:coveragelevel2}, where these smaller intervals result in undercoverage.

\begin{figure}
    \centering 
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{ciwlevel2.png}
        \caption{Level-2 effects}
        \label{fig:ciwlevel2}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{ciwcrosslevel.png}
        \caption{Cross-level interactions}
        \label{fig:ciwcrosslevel}
    \end{subfigure}
    \caption{Width of the 95\% confidence intervals for the level-2 and cross-level effects of the linear mixed model for all simulated datasets over 100 simulations with ICC = .5. Method stan4bart is based on a differing number of dataset simulations described in table \ref{tab:stan4bartsimulations}.}
    \label{fig:ciwlevel2crosslevel}
\end{figure}

\section{Discussion}
The goal of this study was to investigate whether the use of multilevel-BART (M-BART) models in MI could improve performance in the context of missing multilevel data. Even though MI has been implemented in a multilevel context \citep{mistlerComparisonJointModel2017, enders2018, enders2018a, enders2020, buurenFlexibleImputationMissing2018, taljaard2008, enders2016, resche-rigon2018, audigier2018, dong2023, grund2016, grund2018a, grund2018, ludtke2017, grund2021, quartagno2022}, issues rise with the current implementation. Since MLMs are built step-wise with non-linearities, ensuring congeniality between the imputation model and analysis model is difficult. Additionally, mirroring the hierarchical structure of the data in the imputation models is also challenging \citep{buurenFlexibleImputationMissing2018, burgette2010, hox2011} and can result in complex models that might not converge \citep{buurenFlexibleImputationMissing2018}. This study aimed to solve these problems by using BART models in the imputation process. These models --- being non-parametric and tree-based --- are able to implicitly model non-linearities and interactions \citep{hill2020, burgette2010, lin2019, chipman2010, james2021, salditt2023, breiman1984}, alleviating the problems when defining a multilevel imputation model. 

The simulations indicate that out of all investigated imputation methods, the straightforward multilevel imputation method --- 2l.pmm --- had the best overall performance. It showed the least overall bias and most consistent coverage. Furthermore, the width of its confidence intervals oftentimes mimicked the ``true'' data with 0\% missing. On the other hand, the random effects --- i.e. the random slopes, random intercept, and residual variance --- and the cross-level interactions were often biased. Prior research has shown that passive imputation --- where the transformation is done on-the-fly, so it can be included in the imputation model --- yields biased estimates because it doesn't accurately reflect the complex joint distribution \citep{grund2018,vink2013,seaman2012}. Furthermore, some coverage estimates for the fixed effects suggested some efficiency could still be gained. Also, 2l.pmm --- which is based on \texttt{lme4::lme()}, a linear mixed model --- might have an unfair advantage due to the data generating mechanism being based on a multivariate linear mixed model \citep{oberman2023}. % check this sentence

Together with 2l.pmm, stan4bart was a model that could incorporate the most multilevel structure present in the data. While showing some promising results, stan4bart also showed some considerable biases and undercoverages. It seemed to be unable to recover the level-2 effects --- fixed and cross-level. However, we need to consider that stan4bart, compared to 2l.pmm, didn't constrain the level-2 imputations to be the same within groups, thus estimating their variance inaccurately. We can see this, for stan4bart, in the too small estimated variance for the level-2 effects and the overestimated residual variance \citep{buurenFlexibleImputationMissing2018}. Thus, possibly underestimating the level-2 effects and, as a consequence, the cross-level interactions. % the level-2 effects were not specified to be the same across groups like with 2l.pmm, so it might explain the difference in performance to 2l.pmm for both level-2 and cross-level effects. Doove et al. found negative bias for interaction effects with regression trees --> interesting why worse performance than BART. Variance of level-2 effects is too low --> stan4bart does not see the group structure, thus underestimates the variance --> underestimates the level-2 effects.
However, it did show the best performance in terms of the random structure of the data, outperforming 2l.pmm. % here, the random effects were modelled by stan, so consider that
Still, a major disadvantage of this method was its extensive computational time: the imputation of 20 datasets with 50 groups of size 50 took around 3 days to complete\footnote{2 x Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz, 48 cores, 64GB Mem, Nvidia GTX 1080Ti}. % also consider the stan4bart paper? but estimand may be very different from my evaluations.

Most surprising was the performance of rbart, which is a model that should be able to account for some random structure in the data --- namely, intercept variances. However, it had the worst overall performance. Remarkably, it was unable to capture the intercept variance --- underestimating it. rbart only showed acceptable results for some --- not all --- fixed level-1 effects and was outperformed by bart at times. It would be interesting to evaluate the rbart imputation method with data only including random intercepts --- since it is meant to account for that.

Unsurprisingly, single-level imputation methods --- pmm and bart --- were unable to accurately capture the multilevel structure of the data: underestimating level-2 effects, cross-level interactions and the random effects, while still showing acceptable results for the overall intercept and level-1 effects. The undercoverage of the overall intercept and level-1 effects $\gamma_{10}, \gamma_{20}$ and $\gamma_{30}$ as well as their inaccurate confidence interval widths are in line with prior research. Namely, ignoring the multilevel structure results in underestimating the ICC, standard errors, random intercepts, random slopes, and overestimating the residual variance \citep{buurenFlexibleImputationMissing2018, ludtke2017, taljaard2008, hox2011,enders2016}.

Lastly, listwise deletion showed better results than expected: it outperformed 2l.pmm for most parameters. This would be expected under MCAR but not under MAR \citep{buurenFlexibleImputationMissing2018,enders2018a,peeters2015,austin2021,carpenter2013,little2002,grund2018,ludtke2017,grund2021,schouten2021}. Thus, indicating that a special case could have been generated --- much like those mentioned in \citep[§2.7]{buurenFlexibleImputationMissing2018} ---, where listwise deletion outperforms the other imputation methods when the missing data was generated as MAR.

This study had a few limitations. Firstly, due to time restrictions paired with extensive computational time for the imputation methods, only 100 repetitions were used for evaluation.~\citet{morris2019} define a minimum of repetitions in a simulation study based on the required level of precision --- MCSE --- and expected coverage. For an MCSE of 0.5\% and expected coverage of 95\%, they pose that 1900 repetitions are needed. As a result, especially 95\% confidence interval coverage estimates are variable. Secondly, in their current implementation, the bart imputation models --- single-level bart, rbart and stan4bart --- are computationally expensive; taking, at the least, several hours to impute one dataset. Then, this study considered a limited number of factors resulting in a limited picture of the performance of the imputation methods. For example, the amount of missingness was fixed at 50\% and the ICC at 0.5 and, according to previous methodological research, these factors can influence the performance of the imputation methods \citep{enders2018,enders2018a,enders2020,mistler2017,akkayahocagil2023,grund2016,grund2018a,grund2018,ludtke2017,grund2021}. Lastly, the generated MAR mechanism did not mimic the expected characteristic associated with MAR. So, the performance of the imputation methods were not evaluated under a strong MAR mechanism, which is common when evaluating imputation methods \citep{buurenFlexibleImputationMissing2018,enders2018a,peeters2015,austin2021,carpenter2013,little2002,grund2018,ludtke2017,grund2021,schouten2021}. In addition to important because, with real-life data, MCAR can rarely be assumed \citep{oberman2023,buurenFlexibleImputationMissing2018,kang2013,little2002}.

So, avenues for future research include exploring the performance of the M-BART model --- stan4bart --- under a stricter MAR mechanism, or, a MNAR mechanism, which \citet{oberman2023} pose to be a likely real-life missingness mechanism. Thus, for a method to perform well in real-life situations, it should preferably perform well under both MAR and MNAR \citep{oberman2023}. Furthermore, the robustness of stan4bart could be evaluated under different amounts of missingness, different ICCs, and more differing sample sizes to reflect other realistic situations. For example, group sizes of 5 are often found in family-type research \citep{maas2005}. Also, Lower ICCs, lower sample sizes, and a higher amount of missingess could introduce other biases and complexities \citep{enders2018,enders2018a,enders2020,mistler2017,akkayahocagil2023,grund2016,grund2018a,grund2018,ludtke2017,grund2021}. Research could be conducted into the reduction of computational time for stan4bart: reducing the number of posterior samples, thinning samples, burn-in samples, or other specifications for the stan4bart method. Then, lastly, the matching procedure for the predictive mean matching step could be explored. Research could examine how different matching methods to better implement the sampling variability \citep{buurenFlexibleImputationMissing2018} could be implemented and how they would affect the performance of the stan4bart method.

\section{Conclusion}

To sum up, this study aimed to ease the complexities associated with multiple imputation in a multilevel context by using BART models as the imputation models. Being non-parametric and tree-based, BART models were expected to make defining a congenial and well performing imputation model for multilevel data easier. However, the current implementation of a multilevel-BART imputation method did not improve on the current implementation of multilevel predictive mean matching. Meanwhile, also showing inviting results for future research into the multilevel-BART imputation method.

\newpage
\bibliography{thesis}
\addcontentsline{toc}{section}{References}
\bibliographystyle{apalike}

\newpage
\appendix
\section{Imputation functions} \label{appendix:imputationfunctions}
\subsection{BART}
\begin{lstlisting}[language=R, caption = {Imputation function for single-level BART}, label = {lst:singlelevelBART}]
    mice.impute.bart <- function(y, ry, x, wy = NULL, use.matcher = FALSE, donors = 5L, ...) {
        install.on.demand("dbarts", ...)
        if (is.null(wy)) {
            wy <- !ry
        }
    
        # Parameter estimates
        fit <- dbarts::bart(x, y, keeptrees = TRUE, verbose = FALSE)
    
        yhatobs <- fitted(fit, type = "ev", sample = "train")[ry]
        yhatmis <- fitted(fit, type = "ev", sample = "train")[wy]
    
        # Find donors
        if (use.matcher) {
            idx <- matcher(yhatobs, yhatmis, k = donors)
        } else {
            idx <- matchindex(yhatobs, yhatmis, donors)
        }
    
        return(y[ry][idx])
    }
\end{lstlisting}
\subsection{R-BART}
\begin{lstlisting}[language=R, caption={Imputation function for random intercept BART}, label={lst:randominterceptBART}]
    mice.impute.2l.rbart <- function(y, ry, x, wy = NULL, type, use.matcher = FALSE, donors = 5L, ...) {
        install.on.demand("dbarts", ...)
        if (is.null(wy)) {
            wy <- !ry
        }
    
        clust <- names(type[type == -2])
        effects <- names(type[type != -2])
        X <- x[, effects, drop = FALSE]
    
        model <- paste0(
            "y ~ ", paste0(colnames(X), collapse = " + ")
        )
    
        fit <- dbarts::rbart_vi(formula = formula(model), group.by = clust, data = data.frame(y, x), verbose = FALSE, n.threads = 1, n.samples = 500L, n.burn = 500L, ...)
    
        yhatobs <- fitted(fit, type = "ev", sample = "train")[ry]
        yhatmis <- fitted(fit, type = "ev", sample = "train")[wy]
    
        # Find donors
        if (use.matcher) {
            idx <- matcher(yhatobs, yhatmis, k = donors)
        } else {
            idx <- matchindex(yhatobs, yhatmis, donors)
        }
    
        return(y[ry][idx])
    }
\end{lstlisting}
\subsection{stan4bart}
\begin{lstlisting}[language=R, caption={Imputation function for multilevel-BART with random effects and cross-level interactions}, label={lst:multilevelBART}]
    mice.impute.2l.bart <- function(y, ry, x, wy = NULL, type, intercept = TRUE, use.matcher = FALSE, donors = 5L, ...) {
        install.on.demand("stan4bart", ...)
        if (is.null(wy)) {
            wy <- !ry
        }
    
        if (intercept) {
            x <- cbind(1, as.matrix(x))
            type <- c(2, type)
            names(type)[1] <- colnames(x)[1] <- "(Intercept)"
        }
    
        clust <- names(type[type == -2])
        rande <- names(type[type == 2])
        fixe <- names(type[type > 0])
    
        lev <- unique(x[, clust])
    
        X <- x[, fixe, drop = FALSE]
        Z <- x[, rande, drop = FALSE]
        xobs <- x[ry, , drop = FALSE]
        yobs <- y[ry]
        Xobs <- X[ry, , drop = FALSE]
        Zobs <- Z[ry, , drop = FALSE]
    
        # create formula
        fr <- ifelse(length(rande) > 1,
            paste0("+ (1 +", paste(rande[-1L], collapse = "+")),
            " + (1 "
        )
        randmodel <- paste0(
            "y ~ bart(", paste0(fixe[-1L], collapse = " + "), ")",
            fr, "| ", clust, ")"
        )
    fit <- eval(parse(text = paste("stan4bart::stan4bart(", randmodel,
        ", data = data.frame(y, x),
            verbose = -1,
            bart_args = list(k = 2.0, n.samples = 500L, n.burn = 500L, n.thin = 1L, n.threads = 1))",
        collapse = ""
    )))
    
        yhatobs <- fitted(fit, type = "ev", sample = "train")[ry]
        yhatmis <- fitted(fit, type = "ev", sample = "train")[wy]
    
        # Find donors
        if (use.matcher) {
            idx <- matcher(yhatobs, yhatmis, k = donors)
        } else {
            idx <- matchindex(yhatobs, yhatmis, donors)
        }
    
        return(y[ry][idx])
    }
\end{lstlisting}

\end{document}

