\documentclass[10pt, a4paper, titlepage]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx, latexsym}
\usepackage{titling}
\setlength{\droptitle}{-25em}
\renewcommand{\maketitlehooka}{\Large}
\usepackage{setspace}
\usepackage{amssymb, amsmath, amsthm}
\usepackage[export]{adjustbox}
\usepackage{bm}
\usepackage{wrapfig}
\usepackage{epstopdf}
\usepackage{microtype}
\usepackage[hidelinks]{hyperref}
\usepackage{titling}
\hypersetup{
    pdftitle={Thesis Proposal Heleen Brüggen},
    pdfauthor={Heleen Brüggen},
    pdfsubject={Thesis Proposal Heleen Brüggen},
    pdfkeywords={},
    bookmarksnumbered=true,
    bookmarksopen=true,
    bookmarksopenlevel=1,
    colorlinks=false,
    pdfstartview=Fit,
    pdfpagemode=UseNone
}

\singlespacing

\begin{document}
\begin{titlingpage}
\begin{center}
\Huge\textbf{Master Thesis Proposal:  \\ Multilevel Multivariate Imputation by Chained Equations through Bayesian Additive Regression Trees} \\
\Large\textit{Methodology and Statistics for the Behavioural, Biomedical and Social Sciences}

\vspace{.5cm}

\normalsize\textit{Heleen Brüggen}

\vspace{15cm}

\begin{minipage}{0.5\textwidth}
\begin{flushleft}

\textbf{Word count:} \\
\textbf{Candidate Journal:} \\
\textbf{FETC Case Number:} \\
\textbf{Supervisors:} \\
MSc. T. Volker \\
Dr. G. Vink \\
 MSc. H. Oberman
\end{flushleft}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{flushright}

750 \\
Computational Statistics \& Data Analysis \\
23-1778 \\
------------------------\\
Utrecht University \\
Utrecht University \\
Utrecht University
\end{flushright}
\end{minipage}

\end{center}
\end{titlingpage}

\newpage

\section{Introduction}
Incomplete data sets are a common challenge in many different fields. Unlike quick fixes like mean imputation or listwise deletion, multiple imputation is considered a valid method for dealing with incomplete data \cite{mistlerComparisonJointModel2017, buurenFlexibleImputationMissing2018}. With multiple imputation, each missing value is filled in more than once, thereby considering necessary variation associated with the missingness problem. The multiply imputed data sets are analyzed, and the corresponding inferences are pooled \cite{buurenFlexibleImputationMissing2018, austin2021}. Generally, multiple imputation operates under two frameworks: joint modeling and fully conditional specification \cite{mistlerComparisonJointModel2017, buurenFlexibleImputationMissing2018}. Joint modeling (JM) employs a multivariate data distribution and regression model to impute missing values \cite{buurenFlexibleImputationMissing2018, enders2018}. Fully conditional specification (FCS), or chained equations, iteratively imputes one variable with missing values at a time through conditional univariate distributions \cite{enders2018, buurenFlexibleImputationMissing2018}. The JM and FCS approaches are extended to a multilevel imputation context, where data is structured in a hierarchical way (students nested within classes) \cite{mistlerComparisonJointModel2017}.

Currently, the specifications of the imputation models in a multilevel context are quite complex \cite{buurenFlexibleImputationMissing2018}: they should at least be as general as the analysis model \cite{grund2018} and preferably all-encompassing. However, the complexity of the analysis model is built step-wise with non-linearities \cite{hox2017} and a very complex model might not converge \cite{buurenFlexibleImputationMissing2018}. Bayesian Additive Regression Trees (BART) model non-linearities well and automatically through recursive binary partitioning of the predictor space often outperforming other machine learning approaches \cite{hill2020}. Recursive binary partitioning doesn’t assume a specific data form; it divides the predictor space to maximize variance explanation by automatically identifying best fitting splits \cite{hastie2017, james2021, salditt2023}. In a single-level context, the use of tree-based models like regression trees, random forests or BARTs simplified imputation models and performed better than parametric methods: the estimates showed better confidence interval coverage of the population parameters, lower variance and lower bias \cite{burgette2010, xu2016}. Also in a multilevel prediction context, BART provides better estimates with a lower Mean Squared Error (MSE) and lower relative bias compared to the standard multilevel models \cite{wagner2020, chen2020}. However, their use in multiple imputation in a multilevel context is yet to be implemented, even though their performance in a single-level context seems promising \cite{burgette2010, xu2016}. Thus, my research question will be: \textit{Can multivariate imputation by chained equations through a multilevel bayesian additive regression trees model improve the bias, variance and coverage of the estimates in a multilevel context compared to current practices?} Given the success of non-parametric models in single-level multiple imputation, I anticipate that employing multilevel BART models in a multilevel missing data context will reduce bias, accurately model variance, and improve estimate coverage compared to classical multilevel imputation through \textit{21.pmm} in MICE.

\section{Analytic strategy}
We conduct a simulation study in which five factors are varied:
\begin{enumerate}
	\item \textit{Intraclass Correlation} (ICC = 0, .05, .3 and .5)
	\item \textit{Number of clusters} (J = 30 and 50)
	\item \textit{Within-cluster sample size}  ($n_{j}$ = 5, 15, 25 and 50)
	\item \textit{The Missing At Random (MAR) and Missing Completely At Random (MCAR) data rate} (0\%, 25\% and 50\%)
	\item \textit{Within-group effect size:} (size of the regression coefficients $\beta$ = .2, .5 and .8)
\end{enumerate}
All these values are realistic in practice and/or previously proposed \cite{gulliford1999, murray2003, hox2017, grund2018, enders2018a, enders2020}. The ICC can be interpreted as the expected correlation between two randomly sampled individuals from the same group or the proportion of the total variance at the cluster level \cite{gulliford2005, shieh2012, hox2017}. The simulation study will be performed in R with the package MICE \cite{buuren2011} to perform the FCS imputations, which I will enchance by integrating BART. The classical, \textit{21.pmm} in MICE,  FCS multilevel imputation method \cite{ludtke2017, enders2018a, enders2020} and complete case analysis will serve as a benchmark. The population data-generating mechanism will be
\begin{subequations}
\label{eq:population}
\begin{align}
y_{ij} &= \beta_{0j} + \beta_{1j}X_{1ij} + \beta_{2j}X_{2ij} + \epsilon_{ij}, \tag{1.1} \\
\beta_{0j} &= \gamma_{00} + \gamma_{01}Z_{j} + \upsilon_{0j}, \tag{1.2} \\
\beta_{1j} &= \gamma_{10} + \gamma_{11}Z_{j} + \upsilon_{1j}, \tag{1.3} \\
\beta_{2j} &= \gamma_{20} +  \upsilon_{2j}, \tag{1.4}
\end{align}
\end{subequations}
where $y_{ij}$ is a continuous level 1 outcome variable for person $i$ in group $j$ and $Z_j$ is a continuous level 2 variable. The random intercept $\beta_{0j}$ is determined by the grand mean $\gamma_{00}$, the group effect $\gamma_{01}Z_{j}$ and the group-level random residuals $\upsilon_{0j}$. The regression coefficient $\beta_{1j}$ for the continuous variable $X_{1ij}$ depends on the the intercept $\gamma_{10}$, the cross-level interaction $\gamma_{11}Z_{j}$ and the random slopes $\upsilon_{1j}$. For the ordinal variable $X_{2ij}$ (treated as continuous), $\beta_{2j}$ is determined by the intercept $\gamma_{20}$ and the random slopes $\upsilon_{2j}$. The residuals and random slopes $\upsilon_{0j}$, $\upsilon_{1j}$,  $\upsilon_{2j}$, and $\epsilon_{ij}$, and random slopes follow a zero-mean normal distribution. $X_1$, $X_2$ and $Z$ are multivariate normally distributed. The estimates will be evaluated on their relative bias (the difference between the average estimate and the true value), modeled variance and the 95\% confidence interval coverage.

\nocite{*}
\newpage
\bibliography{thesisproposal}
\bibliographystyle{apalike}

\end{document}

